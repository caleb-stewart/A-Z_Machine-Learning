{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caleb-stewart/A-Z_Machine-Learning/blob/main/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Arrays\n",
        "import pandas as pd # Import data set and matrix features\n",
        "import matplotlib.pyplot as plt # Allows us to plot charts\n"
      ],
      "metadata": {
        "id": "n6Kc_IgJHqpI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hold the data.csv data - Dataframe\n",
        "dataset = pd.read_csv(\"Data.csv\")\n",
        "print(dataset.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhHjzIPLIpIq",
        "outputId": "bda5acb7-e87b-4392-b0db-15ff136bdad8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Country', 'Age', 'Salary', 'Purchased'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two entries\n",
        "# Matrix of features and dependent variable vector\n",
        "\n",
        "# Features are the columns you use to predit depedndent variable\n",
        "# Dependent variable is what you want to predict\n",
        "\n",
        "# Take indexes of rows and columns we want to extract\n",
        "features = dataset.iloc[:, :-1].values # We get all rows, and all but last column\n",
        "dep_vars = dataset.iloc[:, -1].values # Only the last column\n",
        "\n",
        "# Features should only have 'Country, Age, Salary\"\n",
        "print(features)\n",
        "\n",
        "# dep_vars should only have \"Purchased\"\n",
        "print(dep_vars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R_xFbcThKvzV",
        "outputId": "02bd0faf-b364-4f4d-f8f7-be79f30dc41c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take care of empty columns or rows\n",
        "# 1. We can ignore observations if we have a large dataset\n",
        "# 2. We can also replace missing data by assigning the average within the column\n",
        "\n",
        "# scikit-learn used for data science\n",
        "from sklearn.impute import SimpleImputer\n",
        "# New SimpleImputer, that will replace nan with the mean of column\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "# Replace only the rows with numbers, not text\n",
        "imputer.fit(features[:, 1:3])\n",
        "# Apply the transformation. This creates a new copy\n",
        "features[:, 1:3] = imputer.transform(features[:, 1:3])\n",
        "# Now all nan are replaced\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Rz_rPDNHlT",
        "outputId": "94c6adc5-8b8c-4bde-8164-9902e288f8db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding. Turning the country column into three columns\n",
        "# This envoles creating binary vectors\n",
        "# This is because our model will have a hard time with Strings and correlation b/w them\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Two arguments:\n",
        "  # Specify what transformation (kind of transf, kind of encoding, index of cols we want)\n",
        "  # Remainder; Keep columns we dont want to encode\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "# Apply to features array, and force to be np\n",
        "features = np.array(ct.fit_transform(features))\n",
        "print(features)\n",
        "\n",
        "# This makes three new columns, each correlating with a country"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2y7u-C7TAFS",
        "outputId": "500d2068-2108-401e-f04f-19787c3ef47c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'yes' and 'no' to 1s and 0s\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Automatically changes yes and no's\n",
        "le = LabelEncoder()\n",
        "dep_vars = le.fit_transform(dep_vars)\n",
        "print(dep_vars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uG8rR8vV1e_",
        "outputId": "bf40f688-0b1b-4653-8cdb-2276305b372d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling before or after splitting ???\n",
        "  # after because the test set is supposed to be a brand new set\n",
        "\n",
        "# We will 4 sets.\n",
        "  # (feature matrix train, feature matrix test) and (dep var train, dep var test)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 80% train, 20% split\n",
        "# also fix the random seed, so we always get the same train and test split\n",
        "feature_train, feature_test, dep_train, dep_test = train_test_split(features, dep_vars, test_size=0.2, random_state=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "FUWyWNSCZfVD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIKCz4CRc2ey",
        "outputId": "6880b49d-f6f1-4d74-db46-7732f3a51f6a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0oszA3Uc4AD",
        "outputId": "82702fb5-40ee-4414-feb0-1e312d4a4474"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dep_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fNo6WYqc8k7",
        "outputId": "443ab79a-3b22-415d-fcda-af16a4b09604"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dep_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as91aCXoc9pf",
        "outputId": "a5f6308e-3226-4efc-f433-b8940eb19600"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We do this to avoid some features being dominated by other features\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler() # This uses standard deviation (values betwee -3 and 3)\n",
        "\n",
        "# We dont feature scale our encoding, because they are already in an appropriate range\n",
        "feature_train[:, 3:] = sc.fit_transform(feature_train[:, 3:])\n",
        "feature_test[:, 3:] = sc.transform(feature_test[:, 3:])"
      ],
      "metadata": {
        "id": "oOCpUqHIf0El"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPwxArC5hMsd",
        "outputId": "33d19567-16c3-4e96-b3f1-2ee7d980059a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPC6xhTphPKx",
        "outputId": "919c7c27-4e90-4b03-fe6e-0b72e3d67644"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    }
  ]
}